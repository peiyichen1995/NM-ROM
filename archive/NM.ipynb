{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from scipy.integrate import solve_ivp\n",
    "from numpy.linalg import inv\n",
    "import tensorflow as tf\n",
    "from dolfin import *\n",
    "from ffc.fiatinterface import create_quadrature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Model parameters\n",
    "############################\n",
    "method = \"NM_ROM\"\n",
    "nu = 0.1\n",
    "A = 0.5\n",
    "filename = \"output/burgers_1D/nu_\" + str(nu) + \"/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Read snapshots\n",
    "############################\n",
    "print(\"Reading mesh and solution of the full order model\")\n",
    "mesh, u_ref = read_mesh_and_function(filename + \"FOM\", \"u\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Perform AutoEncoding\n",
    "# R: number of dofs in the full order model\n",
    "# r: number of dofs in the reduced order model\n",
    "############################\n",
    "\n",
    "# This is the number of dofs in the reduced order model\n",
    "n = 15\n",
    "\n",
    "N, time_steps = u_ref.shape\n",
    "\n",
    "# split test and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    u_ref.T, u_ref.T, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(N, ))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "# encoded = layers.Dense(r, activation='sigmoid')(input_img)\n",
    "encoded = layers.Normalization()(input_img)\n",
    "encoded = layers.Dense(2000, activation='linear')(encoded)\n",
    "encoded = layers.Dense(n, activation='linear')(encoded)\n",
    "\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = layers.Dense(N, activation='linear', kernel_constraint=tf.keras.constraints.NonNeg())(encoded)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "\n",
    "# This model maps an input to its encoded representation\n",
    "encoder = keras.Model(input_img, encoded)\n",
    "\n",
    "# This is our encoded (32-dimensional) input\n",
    "encoded_input = keras.Input(shape=(n,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# Create the decoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
    "# decoder = keras.Model(encoded_input, autoencoder.layers[-1](autoencoder.layers[-2](encoded_input)))\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "# opt = tf.keras.optimizers.SGD(\n",
    "#     learning_rate=0.01\n",
    "# )\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "autoencoder.compile(optimizer=opt, loss='mean_squared_error')\n",
    "\n",
    "class fewerPrintouts(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, interval):\n",
    "        self.interval = interval\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.interval == 0:\n",
    "            print('Epoch {}, loss = {}, val_loss = {}'.format(epoch, logs['loss'], logs['val_loss']))\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5,\n",
    "                              patience=10, min_lr=1e-6,verbose=1)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=200)\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=num_epochs,\n",
    "                batch_size=20,\n",
    "                validation_data=(X_test, X_test),\n",
    "                verbose=0,\n",
    "                callbacks=[fewerPrintouts(10),early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Function space\n",
    "############################\n",
    "V = FunctionSpace(mesh, \"CG\", 1)\n",
    "\n",
    "############################\n",
    "# Functions\n",
    "############################\n",
    "u = Function(V)\n",
    "u_old = Function(V)\n",
    "u0 = Function(V)\n",
    "v = TestFunction(V)\n",
    "\n",
    "############################\n",
    "# Initial condition\n",
    "############################\n",
    "u0_expr = Expression(\n",
    "    \"x[0] < 1 ? 1+A*(sin(2*pi*x[0]-pi/2)+1) : 1\", degree=1, A=A)\n",
    "u0.interpolate(u0_expr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Time control\n",
    "############################\n",
    "t_start = 0.0\n",
    "t_final = 0.5\n",
    "t_steps = 500\n",
    "t_sequence = np.linspace(t_start, t_final, t_steps + 1)\n",
    "dt = (t_final - t_start) / t_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(red_vec):\n",
    "    return tf.reshape(decoder(tf.reshape(red_vec, [1,-1])), [N])\n",
    "\n",
    "def encode(vec):\n",
    "    return encoder(tf.reshape(vec, [1,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe = FiniteElement(\n",
    "    family = \"Quadrature\",\n",
    "    cell = mesh.ufl_cell(),\n",
    "    degree = 2,\n",
    "    quad_scheme=\"default\"\n",
    "    )\n",
    "Q = FunctionSpace(mesh, qe)\n",
    "Qe = Q.element()\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def objective(ur, ur_old):\n",
    "    def residual_(v, grad_v, u, grad_u, u_old):\n",
    "        return v*(u-u_old)/dt-nu*tf.tensordot(grad_v,grad_u,1)+v*grad_u[0]*u\n",
    "    \n",
    "    ut = decoder(ur)\n",
    "    ut_old = decoder(ur_old)\n",
    "    \n",
    "    result = 0\n",
    "\n",
    "    for e in range(mesh.num_cells()):\n",
    "        cell = Cell(mesh, e)\n",
    "        dofs = V.dofmap().cell_dofs(e)\n",
    "        coordinates = cell.get_coordinate_dofs()\n",
    "        ref_points, weights = create_quadrature(mesh.ufl_cell(), 2)\n",
    "        qpoints = Q.element().tabulate_dof_coordinates(cell)\n",
    "        ut_cell = tf.gather(ut[0],dofs)\n",
    "        ut_old_cell = tf.gather(ut_old[0],dofs)\n",
    "        \n",
    "        for qp,weight in enumerate(weights):\n",
    "            qpoint = qpoints[qp]\n",
    "            v_ = V.element().evaluate_basis_all(qpoint, coordinates, cell.orientation()).astype('float32')\n",
    "            grad_v_ = V.element().evaluate_basis_derivatives_all(1, qpoint, coordinates, cell.orientation()).reshape(2,2).astype('float32')\n",
    "            u_qp = tf.tensordot(v_, ut_cell, 1)\n",
    "            u_old_qp = tf.tensordot(v_, ut_old_cell, 1)\n",
    "            grad_u_qp = tf.tensordot(grad_v_, ut_cell, 1)\n",
    "            detJ = np.abs(coordinates[0]-coordinates[2])\n",
    "            r_qp = residual_(v_[qp], grad_v_[qp], u_qp, grad_u_qp, u_old_qp)\n",
    "            result = result + r_qp * detJ * weight\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_and_jacobian(ur, ur_old):\n",
    "    with tf.GradientTape() as t2:\n",
    "        t2.watch(ur)\n",
    "        with tf.GradientTape() as t1:\n",
    "            t1.watch(ur)\n",
    "            obj = objective(ur, ur_old)\n",
    "        r = t1.gradient(obj, ur)\n",
    "    J = t2.jacobian(r, ur)\n",
    "    return r, J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur0 = encode(u0.vector().get_local())\n",
    "ur = tf.identity(ur0)\n",
    "r, J = residual_and_jacobian(ur, ur0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_form = (dot(v, (u - u_old) / Constant(dt)) - inner(nu * grad(u), grad(v)) + inner(u.dx(0) * u, v)) * dx\n",
    "# dr_form_dD = derivative(r_form, u)\n",
    "\n",
    "# def Jacobian(ur):\n",
    "#     with tf.GradientTape() as g:\n",
    "#         ur_reshaped = tf.reshape(ur, [1,-1])\n",
    "#         g.watch(ur_reshaped)\n",
    "#         D = decoder(ur_reshaped)\n",
    "#         dD_dur = g.jacobian(D, ur_reshaped).numpy()[0,:,0,:]\n",
    "#         D = tf.reshape(D, [N])\n",
    "\n",
    "#     u.vector().set_local(D.numpy())\n",
    "#     dr_dD = assemble(dr_form_dD).array()\n",
    "\n",
    "#     J = np.matmul(dr_dD, dD_dur)\n",
    "#     return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(u, RTOL=1e-5, ATOL=1e-6):\n",
    "    def orthogonalize(J, r):\n",
    "        return np.matmul(J.T, r)\n",
    "\n",
    "    def converged(r, r0):\n",
    "        if np.linalg.norm(r) < ATOL:\n",
    "            return True\n",
    "        if np.linalg.norm(r) < RTOL * np.linalg.norm(r0):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    r = residual(u)\n",
    "    J = Jacobian(u)\n",
    "\n",
    "    r0 = orthogonalize(J, r)\n",
    "\n",
    "    for itr in range(50):\n",
    "        print('Itr = {:}, |R| = {:}'.format(itr, np.linalg.norm(orthogonalize(J,r))))\n",
    "\n",
    "        if converged(orthogonalize(J, r), r0):\n",
    "            return u\n",
    "        \n",
    "        du = - np.matmul(np.linalg.inv(np.matmul(J.T, J)), orthogonalize(J, r))\n",
    "        u = u + du\n",
    "        \n",
    "        r = residual(u)\n",
    "        J = Jacobian(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur0 = encode(u0.vector().get_local())\n",
    "ur = tf.identity(ur0)\n",
    "\n",
    "u_approx = np.zeros((N, time_steps))\n",
    "\n",
    "for i, t in enumerate(t_sequence):\n",
    "    print('step = {}, t = {}'.format(i, t))\n",
    "    u_old.vector().set_local(decode(ur).numpy())\n",
    "    ur = solve(ur,1e-3,1e-3)\n",
    "    u_approx[:,i] = decode(ur).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(u_approx, aspect='auto', cmap='jet', vmin=1, vmax=2)\n",
    "cb = fig.colorbar(im)\n",
    "# ax.set_xlabel(\"$t$\")\n",
    "# ax.set_ylabel(\"$x$\")\n",
    "# ax.set_xticks(np.linspace(0, t_steps, 3))\n",
    "# ax.set_xticklabels(np.linspace(t_start, t_final, 3))\n",
    "# ytick_loc = np.linspace(0, V.dim() - 1, 3).astype(int)\n",
    "# ax.set_yticks(ytick_loc)\n",
    "# ax.set_yticklabels(V.tabulate_dof_coordinates()[ytick_loc, 0])\n",
    "# plt.tight_layout(pad=0)\n",
    "# plt.savefig(filename + \"ref.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8475a232b822aed66d3bbbb71d7fb1340252d4f7b77b0b9050f60cc7b3f466a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('fenics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
